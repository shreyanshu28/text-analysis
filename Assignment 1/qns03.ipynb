{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import Levenshtein\n",
    "import html\n",
    "import PyPDF2\n",
    "import datetime\n",
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import sys\n",
    "import fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = open('/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/wegweiser_senioren.pdf','rb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyPDF2 text extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "#file01 = open(r'/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/output_file_pypdf1.txt','w')\n",
    "with open('/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/wegweiser_senioren.pdf','rb') as pdf_file:\n",
    "    read_pdf = PyPDF2.PdfFileReader(pdf_file)\n",
    "    number_of_pages = read_pdf.getNumPages()\n",
    "    pypdf_test = ''\n",
    "    for pg_no in range(number_of_pages): \n",
    "        page = read_pdf.getPage(pg_no)\n",
    "        page_content = page.extractText()\n",
    "        #file01.writelines(page_content)\n",
    "        pypdf_test += page_content\n",
    "        \n",
    "        \n",
    "#file01.close()        \n",
    "stop = datetime.datetime.now()\n",
    "pypdf_time = stop - now\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyMuPDF text extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file1 = open('/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/wegweiser_senioren.pdf')\n",
    "now = datetime.datetime.now()\n",
    "#file02 = open(r'/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/output_file_pymupdf.txt','w')\n",
    "\n",
    "doc = fitz.open(input_file1)  \n",
    "text = ''\n",
    "for page in doc:  \n",
    "    text += page.get_text() \n",
    "\n",
    "pymupdf_test = text\n",
    "#file02.writelines(pymupdf_test) \n",
    "#file02.close()\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "pymupdf_time = stop - now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using NLP method parser from Tika Module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "now = datetime.datetime.now()\n",
    "file_data = parser.from_file('/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/wegweiser_senioren.pdf')\n",
    " \n",
    "# file_data['content'] is used to get the content of the pdf file.\n",
    "\n",
    "output = file_data['content']\n",
    "\n",
    "# This output.encode encodes the text into utf-8 format.\n",
    "\n",
    "output1 = output.encode('utf-8', errors='ignore')\n",
    " \n",
    "# finally it saves the text file to a file called output.txt.\n",
    "\n",
    "#with open('/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/output_file4546.txt', 'w') as the_file:\n",
    "    #the_file.write(str(output1))\n",
    "tika_time = stop - now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline text file (converted the given pdf to txt using online pdf converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "\n",
    "f = open('/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/wegweiser_senioren.txt', \"r\", encoding=\"utf8\")\n",
    "baseline = f.read()\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "base_time = stop - now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity for PypDF2:\n",
      "0.9999616482818724\n",
      "Cosine similarity for MuPdf:\n",
      "0.9999666704679816\n",
      "Cosine similarity for tika:\n",
      "0.9998491826986143\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "def clean_string(text):\n",
    "    text = ''.join([word for word in text if word not in string.punctuation])\n",
    "    text = text.lower()\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords])\n",
    "    return text\n",
    "\n",
    "corpi = [baseline,pypdf_test,pymupdf_test,output]\n",
    "\n",
    "corpi = list(map(clean_string, corpi))\n",
    "\n",
    "vectorizer = CountVectorizer().fit_transform(corpi)\n",
    "vectors = vectorizer.toarray()\n",
    "\n",
    "cosim = cosine_similarity(vectors)\n",
    "\n",
    "def cosine_sim_vectors(vec1, vec2):\n",
    "    vec1 = vec1.reshape(1, -1)\n",
    "    vec2 = vec2.reshape(1, -1)\n",
    "    return cosine_similarity(vec1, vec2)[0][0]\n",
    "\n",
    "print(\"Cosine similarity for PypDF2:\")\n",
    "print(cosine_sim_vectors(vectors[0], vectors[1]))\n",
    "print(\"Cosine similarity for MuPdf:\")\n",
    "print(cosine_sim_vectors(vectors[0], vectors[2]))\n",
    "print(\"Cosine similarity for tika:\")\n",
    "print(cosine_sim_vectors(vectors[0], vectors[3]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TDF-idf Similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_string_similarity_test(correct_string,test_string):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    two_strings = [correct_string,test_string]\n",
    "    vect = TfidfVectorizer(min_df=1, stop_words=\"english\")\n",
    "    tfidf = vect.fit_transform(two_strings)\n",
    "    pairwise_similarity = tfidf * tfidf.T\n",
    "    arr = pairwise_similarity.toarray()\n",
    "    np.fill_diagonal(arr, -1)\n",
    "    return arr[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf similarity for PyPDF2:\n",
      "0.9999711754667839\n",
      "Tfidf similarity for PDFminer_six:\n",
      "0.9999711754667839\n",
      "Tfidf similarity for Tika:\n",
      "0.9998676758240562\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Tfidf similarity for PyPDF2:\")\n",
    "print(tfidf_string_similarity_test(baseline, pypdf_test))\n",
    "print(\"Tfidf similarity for PDFminer_six:\")\n",
    "print(tfidf_string_similarity_test(baseline, pymupdf_test))\n",
    "print(\"Tfidf similarity for Tika:\")\n",
    "print(tfidf_string_similarity_test(baseline, output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Time taken to extract the data ': [base_time, pypdf_time,pymupdf_time,tika_time],\n",
    "        'Cosine similarity': [cosine_sim_vectors(vectors[0], vectors[0]), cosine_sim_vectors(vectors[0], vectors[1]), cosine_sim_vectors(vectors[0], vectors[2]), cosine_sim_vectors(vectors[0], vectors[3])],\n",
    "        'Tf-idf similarity': [tfidf_string_similarity_test(baseline, baseline), tfidf_string_similarity_test(baseline, pypdf_test), tfidf_string_similarity_test(baseline, pymupdf_test),tfidf_string_similarity_test(baseline, output)]\n",
    "        }\n",
    "df = pd.DataFrame(data, index=['Baseline_string', 'PyPdf', 'PyMuPdf', 'Tika'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time taken to extract the data</th>\n",
       "      <th>Cosine similarity</th>\n",
       "      <th>Tf-idf similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline_string</th>\n",
       "      <td>0 days 00:00:00.001995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PyPdf</th>\n",
       "      <td>0 days 00:00:01.505429</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.999971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PyMuPdf</th>\n",
       "      <td>0 days 00:00:00.109780</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.999971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tika</th>\n",
       "      <td>-1 days +23:59:35.247835</td>\n",
       "      <td>0.999849</td>\n",
       "      <td>0.999868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time taken to extract the data   Cosine similarity  \\\n",
       "Baseline_string          0 days 00:00:00.001995           1.000000   \n",
       "PyPdf                    0 days 00:00:01.505429           0.999962   \n",
       "PyMuPdf                  0 days 00:00:00.109780           0.999967   \n",
       "Tika                   -1 days +23:59:35.247835           0.999849   \n",
       "\n",
       "                 Tf-idf similarity  \n",
       "Baseline_string           1.000000  \n",
       "PyPdf                     0.999971  \n",
       "PyMuPdf                   0.999971  \n",
       "Tika                      0.999868  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. The Tf-idf similarity is almost the same for PyPdf and PyMuPdf.\n",
    "### 2. The Baseline_string is compared to itself hence the score is 1 (used for comparation with other methods)\n",
    "### 3. The time take to convert the same file is faster in case PyMuPdf is the winner in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SequenceMatcher to compare the pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_txt = open('/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/wegweiser_senioren.txt')\n",
    "read_baseline = baseline_txt.readlines()\n",
    "input_file_mupypdf = open('/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/output_file_pymupdf.txt')\n",
    "read_mupypdf = input_file_mupypdf.readlines()\n",
    "input_file_pypdf = open('/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/output_file_pypdf.txt')\n",
    "read_pypdf = input_file_pypdf.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "sequenceScore = SequenceMatcher(None, read_baseline, read_mupypdf)\n",
    "check_list = sequenceScore.ratio()*100\n",
    "check_list = round(check_list,1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2 textfiles are 74.1 similar\n"
     ]
    }
   ],
   "source": [
    "print(f'The 2 textfiles are {check_list} similar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "sequenceScore = SequenceMatcher(None, read_baseline, read_pypdf)\n",
    "check_list = sequenceScore.ratio()*100\n",
    "check_list = round(check_list,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2 textfiles are 0.0 similar\n"
     ]
    }
   ],
   "source": [
    "print(f'The 2 textfiles are {check_list} similar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('TA')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83da7d17b6647d10c3f2d34ae4dc77c82542c152e525a91063b164b51b15394f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
