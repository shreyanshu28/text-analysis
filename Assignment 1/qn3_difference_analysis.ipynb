{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import Levenshtein\n",
    "import html\n",
    "import PyPDF2\n",
    "import datetime\n",
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import sys\n",
    "import fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = open('/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/wegweiser_senioren.pdf','rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "file01 = open(r'/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/exp1.txt','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF4\n",
    "with open('/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/wegweiser_senioren.pdf','rb') as f:\n",
    "    reader = PyPDF4.PdfFileReader(f)\n",
    "    page = reader.getPage(1)\n",
    "    text = page.extractText()\n",
    "    file01.writelines(text)\n",
    "file01.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "file01 = open(r'/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/exp2.txt','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "\n",
    "doc = fitz.open('/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/wegweiser_senioren.pdf')\n",
    "page = doc[1]\n",
    "text = page.get_text(\"text\",flags=1+2+8)\n",
    "file01.writelines(text)\n",
    "file01.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = open('/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/test01.txt', \"r\", encoding=\"utf8\")\n",
    "baseline = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## comparing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_pypdf = open('/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/exp1.txt')\n",
    "read_pypdf = input_file_pypdf.readlines()\n",
    "input_file_mupypdf = open('/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/exp2.txt')\n",
    "read_mupypdf = input_file_mupypdf.readlines()\n",
    "baseline_file = open('/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/test01.txt')\n",
    "read_baseline = baseline_file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "sequenceScore = SequenceMatcher(None, read_pypdf, read_mupypdf)\n",
    "check_list = sequenceScore.ratio()*100\n",
    "check_list = round(check_list,1) \n",
    "input_file_pypdf.close()\n",
    "input_file_mupypdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "sequenceScore = SequenceMatcher(None, read_baseline, read_mupypdf)\n",
    "check_list = sequenceScore.ratio()*100\n",
    "check_list = round(check_list,1) \n",
    "input_file_pypdf.close()\n",
    "input_file_mupypdf.close()\n",
    "baseline_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "sequenceScore = SequenceMatcher(None, read_baseline, read_pypdf)\n",
    "check_list = sequenceScore.ratio()*100\n",
    "check_list = round(check_list,1) \n",
    "input_file_pypdf.close()\n",
    "input_file_mupypdf.close()\n",
    "baseline_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The provided files are split into three groups. For each of the individual parts, make sure to print out all extracted results into a dedicated text file which should be included in your submission. Each line should contain only a single instance in a normalized format. For phone numbers, e.g., you could remove all spaces and special characters, etc.:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the pdf provided, since each of them are in different format (some have images,tables only and paragraghs)\n",
    "I am using 2 methods for each and apply for all the pdf:\n",
    "1. MymuPdf to convert the paragraghs and images \n",
    "2. tabula-py to extract the tables from pdf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pdf from flyers folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = fitz.open('/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/bahnstadt.pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the text:\n",
    "for pagenumber,page in enumerate(file1.pages(),start=1):\n",
    "    text = page.get_text()\n",
    "    txt = open(f'/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/text_0nly /flyers_pdf_page_{pagenumber}.txt','a')\n",
    "    txt.writelines(text)\n",
    "    txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Found a total of 3 images in page 0\n",
      "[+] Found a total of 2 images in page 1\n",
      "[+] Found a total of 5 images in page 2\n",
      "[+] Found a total of 7 images in page 3\n",
      "[+] Found a total of 2 images in page 4\n",
      "[+] Found a total of 5 images in page 5\n",
      "[+] Found a total of 4 images in page 6\n",
      "[+] Found a total of 1 images in page 7\n",
      "[+] Found a total of 1 images in page 8\n",
      "[+] Found a total of 1 images in page 9\n",
      "[+] Found a total of 2 images in page 10\n",
      "[+] Found a total of 3 images in page 11\n",
      "[+] Found a total of 1 images in page 12\n",
      "[+] Found a total of 3 images in page 13\n",
      "[+] Found a total of 15 images in page 14\n",
      "[+] Found a total of 2 images in page 15\n",
      "[+] Found a total of 3 images in page 16\n",
      "[+] Found a total of 76 images in page 17\n",
      "[+] Found a total of 2 images in page 18\n",
      "[+] Found a total of 3 images in page 19\n",
      "[+] Found a total of 1 images in page 20\n",
      "[+] Found a total of 4 images in page 21\n",
      "[+] Found a total of 2 images in page 22\n",
      "[+] Found a total of 4 images in page 23\n",
      "[+] Found a total of 4 images in page 24\n",
      "[+] Found a total of 1 images in page 25\n",
      "[+] Found a total of 3 images in page 26\n",
      "[+] Found a total of 5 images in page 27\n",
      "[+] Found a total of 2 images in page 28\n",
      "[+] Found a total of 7 images in page 29\n",
      "[+] Found a total of 2 images in page 30\n",
      "[+] Found a total of 113 images in page 31\n",
      "[+] Found a total of 3 images in page 32\n",
      "[+] Found a total of 47 images in page 33\n",
      "[+] Found a total of 2 images in page 34\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "from PIL import Image\n",
    "for page_index in range(len(file1)):\n",
    "    # get the page itself\n",
    "    page = file1[page_index]\n",
    "    # get image list\n",
    "    image_list = page.get_images()\n",
    "    # printing number of images found in this page\n",
    "    if image_list:\n",
    "        print(f\"[+] Found a total of {len(image_list)} images in page {page_index}\")\n",
    "    else:\n",
    "        print(\"[!] No images found on page\", page_index)\n",
    "    for image_index, img in enumerate(image_list, start=1):\n",
    "        # get the XREF of the image\n",
    "        xref = img[0]\n",
    "        # extract the image bytes\n",
    "        base_image = file1.extract_image(xref)\n",
    "        image_bytes = base_image[\"image\"]\n",
    "        # get the image extension\n",
    "        image_ext = base_image[\"ext\"]\n",
    "        # load it to PIL\n",
    "        image = Image.open(io.BytesIO(image_bytes))\n",
    "        # save it to local disk\n",
    "        image.save(open(f\"/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/pdf_to_text/image{page_index+1}_{image_index}.{image_ext}\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad type: 'stream'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m     pix\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/pdf_to_text/\u001b[39m\u001b[39m{\u001b[39;00mxref\u001b[39m}\u001b[39;00m\u001b[39m.png\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     \u001b[39m#if not pix.colorspace.name in (fitz.csGRAY.name, fitz.csRGB.name):\u001b[39;00m\n\u001b[1;32m     13\u001b[0m         \u001b[39m#pix1 = fitz.Pixmap(fitz.csRGB, pix)\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     pix1 \u001b[39m=\u001b[39m fitz\u001b[39m.\u001b[39;49mopen(fitz\u001b[39m.\u001b[39;49mcsRGB,pix)\n\u001b[1;32m     15\u001b[0m     pix1\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/pdf_to_text/\u001b[39m\u001b[39m{\u001b[39;00mxref\u001b[39m}\u001b[39;00m\u001b[39m.png\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m     pix1 \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Sem01/DataScience_for_text_analytics/Assignments/virtualenv/TA/lib/python3.10/site-packages/fitz/fitz.py:3935\u001b[0m, in \u001b[0;36mDocument.__init__\u001b[0;34m(self, filename, stream, filetype, rect, width, height, fontsize)\u001b[0m\n\u001b[1;32m   3933\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3934\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbad type: \u001b[39m\u001b[39m'\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 3935\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[1;32m   3936\u001b[0m stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream\n\u001b[1;32m   3937\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (filename \u001b[39mor\u001b[39;00m filetype):\n",
      "\u001b[0;31mTypeError\u001b[0m: bad type: 'stream'"
     ]
    }
   ],
   "source": [
    "# #import streamlit as st\n",
    "\n",
    "# #uploaded_pdf = st.file_uploader(\"Load pdf: \", type=['pdf'])\n",
    "\n",
    "# /* image_list =file1.get_page_images(0)\n",
    "# for img in image_list:\n",
    "#     xref = img[0]\n",
    "#     pix = fitz.Pixmap(file1,xref)\n",
    "#     if pix.n - pix.alpha < 4:\n",
    "#         pix.save(f'/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/pdf_to_text/{xref}.png')\n",
    "#     else:\n",
    "#         #if not pix.colorspace.name in (fitz.csGRAY.name, fitz.csRGB.name):\n",
    "#             #pix1 = fitz.Pixmap(fitz.csRGB, pix)\n",
    "#         pix1 = fitz.open(fitz.csRGB,pix)\n",
    "#         pix1.save(f'/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/pdf_to_text/{xref}.png')\n",
    "#         pix1 = None\n",
    "#     pix = None\n",
    "# print(len(image_list),'detected') */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1288, 0, 586, 831, 8, 'DeviceCMYK', '', 'Im0', 'DCTDecode'), (1290, 0, 306, 241, 8, 'DeviceCMYK', '', 'Im1', 'DCTDecode'), (1292, 0, 282, 243, 8, 'DeviceCMYK', '', 'Im2', 'DCTDecode')]\n"
     ]
    }
   ],
   "source": [
    "image_list =file1.get_page_images(0)\n",
    "print(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Found a total of 3 images in page 0\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/img_only/img1_1.jpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(io\u001b[39m.\u001b[39mBytesIO(image_bytes))\n\u001b[1;32m     28\u001b[0m \u001b[39m# save it to local disk\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m image\u001b[39m.\u001b[39;49msave(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/img_only/img\u001b[39;49m\u001b[39m{\u001b[39;49;00mpage_index\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mimage_index\u001b[39m}\u001b[39;49;00m\u001b[39m.\u001b[39;49m\u001b[39m{\u001b[39;49;00mimage_ext\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/Sem01/DataScience_for_text_analytics/Assignments/virtualenv/TA/lib/python3.10/site-packages/PIL/Image.py:2350\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2348\u001b[0m         fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39mopen(filename, \u001b[39m\"\u001b[39m\u001b[39mr+b\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2349\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2350\u001b[0m         fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mw+b\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   2352\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   2353\u001b[0m     save_handler(\u001b[39mself\u001b[39m, fp, filename)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/anureddy/Desktop/Sem01/DataScience_for_text_analytics/Assignments/1-3-pdf-files/flyers/img_only/img1_1.jpeg'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('TA': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83da7d17b6647d10c3f2d34ae4dc77c82542c152e525a91063b164b51b15394f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
