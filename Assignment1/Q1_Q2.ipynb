{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1.1** \n",
    "-  Driver: since the main oncern is still to be decided based on the data obtained, this would be the typical text-driven problem where we derive conclusions and decisions stemming from the collected data itself.\n",
    "-  Objective: the main objective of analyzing costumer data is to reach higher profit by better tailoring to specific customer needs. \n",
    "-  Data Availability: The scanned version of insurance paperworks would need further processing: conversion into raw text, cleaning, parsing etc. \n",
    "-  Cost factors: The cost of data gathering must be considered as necessary conversion&cleaning should be carried out, as well as the possible tranformation between formats. \n",
    "\n",
    "**1.1.2** \n",
    "-  Advantage:\n",
    "\n",
    "Elasticsearch adapts the inverted index system of Lucene to offer speedy full-text searches, while traditional RDBMS based on SQL query could be relatively slower in response. The structuralized JSON documents where elasticsearch stores its data could be visited from any node instantly, reducing the number of read operations required.\n",
    "\n",
    "Elasticsearch does not require user to specify the schema of its index; it performs well in auto-inference for datatypes such as number, boolean values and timestamps, offering certain flexibility in storage, while PostgreSQL operates on a rather rigid schema definition basis. \n",
    "\n",
    "-  Disadvantage:\n",
    "\n",
    "The above can be also the drawback for elasticsearch, as PostgreSQL offers a plethora of functionalities based on its support of multiple data types.\n",
    "\n",
    "Elasticsearch also sacrifices certain functionalities---such as transaction---for higher speed, while PostgreSQL supports a broader range of mechanisms including a robust transaction mechanism, while user can either roll back the operation to a given point or bundle operation together.\n",
    "\n",
    "Elasticsearch has a more loose security system where every user is granted the same access as admin, while PostgreSQL tend to apply strict access control with multiple authentications for example LDAP etc.\n",
    "\n",
    "Generally, based on the CAP theorem, what Elasticsearch offers is Availability and Partition Tolerance, while PostgreSQL offers Consistency and Availability. \n",
    "\n",
    "**1.1.3** \n",
    "**Stop word removal** \n",
    "-  Advantage: \n",
    "1. In certain scenarios where stop words are trivial (sentiment analysis, theme classification etc.), its removal would reduce corpus size greatly and keep the information provided by the corpus clean-cut and better fitting for classification or clustering. Example:\n",
    "\n",
    " \"There are 5 people who are unsatisfied about the Mensa food today.\"->[\"unsatisfied\" \"food\"]. \n",
    " \n",
    "The important keywords for sentiment are preserved while trivialities are cut down, word count decrease from 12 to 2. It lowers both the space dimension and data size greatly.\n",
    "2. As the more significant words are preserved, the enhanced datasets with less noise should benefit training accuracy, training speed and model performance.\n",
    "\n",
    "-  Disadvantage:\n",
    "1. Inappropriate stop word removal could change the meaning of text drastically. For example if consider \"not\" as a stop word (as in Aruana) and remove it, \"The food is not good\" -> [\"food\" \"good\"], which is misleading. Sentiment analysis is sensitive to the stop words one select, and one should be careful of not leaving deciding features out. \n",
    "\n",
    "2. Object consisting of certain \"stop words\" would be unintelligible. example for search engine:\n",
    "\n",
    "\"to be or not to be, that is the question\"->[\"question\"]\n",
    "\n",
    "\"take that\" ->[]\n",
    "\n",
    "3. Problems arise because of loss of contexts due to stop word removal.\\\n",
    "Example as on slides:\n",
    "\n",
    "[\"Jill\" \"reported\" \"CEO\" \"company\"]<-\"Jill reported to the CEO of the company\" or \"Jill reported as the CEO of the company\".\n",
    "\n",
    "If the model is not word-based but sequence-based, the training would encounter problems due to linguistic ambiguity. Thus stop word removal should not be considered if the preprocess is not specifically for word-based methods. \n",
    "\n",
    "**Stemming** \n",
    "-  Advantage: \n",
    "1. reduces size of datasets when using bag-of-words methods for assembling different forms of the same word together. For example: \n",
    "\n",
    "[\"liking\" \"likes\" \"liked\"] -> [\"like\"]\n",
    "\n",
    "2. increases processing speed. Stemming, as the purely algorithmic process, is often faster to use than applying word variants, since it does not require any further operation or context information.\n",
    "-  Disadvantage:\n",
    "1. Stemming certain words is not possible, as stemmers regularly can't recognize variants that deviate from the general grammar rules for example \"good\" and \"better\" and \"best\". (\"So why not substitute it with \"goodest\"?\"...Here is when the Orwellian Newspeak comes into use.)\n",
    "2. Stemmed words can be ambiguous, for example Axes is plural for both Ax and Axis. This is called under-stemming, as roots and words are not always corresponding on a one-to-one basis.\n",
    "3. There is also the phenomenon of over-stemming when words of very different meaning are stemmed into the same root. Basic example: while \"the likes of\" means \"things similar to\", \"like\" is also used as a verb. When \"likes\" as noun is stemmed and you are doing word-based sentiment analysis, it might be misleading. More example:  \"farther\" and \"farthing\" would be both stemmed into \"farth\" while their meanings differ greatly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Implement your own (basic) regular expression parser, which can accept or reject a RegEx statement.\n",
    "Consider the following specifications for your RegEx grammar that should be supported.\n",
    "You are not allowed to use any RegEx library, such as Python’s re or regex modules, for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def german_to_ascii(exp):\n",
    "    if \"ß\" in exp:\n",
    "        exp = exp.replace(\"ß\", \"\")\n",
    "    if \"ä\" in exp:\n",
    "        exp = exp.replace(\"ä\", \"\")\n",
    "    if \"ü\" in exp:\n",
    "        exp = exp.replace(\"ü\", \"\")\n",
    "    if \"ö\" in exp:\n",
    "        exp = exp.replace(\"ö\", \"\")\n",
    "    return exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_regex(exp, sequence=[\"^\", \"|\", \"*\", \"+\", \"?\"]):\n",
    "    #german letters\n",
    "    stack = []\n",
    "    exp = german_to_ascii(exp)\n",
    "    \n",
    "    #special chars sequence\n",
    "    for r in range(len(exp) - 1):\n",
    "        if exp[r] in sequence and exp[r+1] in sequence:\n",
    "            return False\n",
    "\n",
    "\n",
    "    for char in exp:\n",
    "        if char in [\"(\"]:\n",
    "            stack.append(char)\n",
    "        else:\n",
    "            if not stack:\n",
    "                return False\n",
    "            current_char = stack.pop()\n",
    "            if current_char == '(':\n",
    "                if char != \")\":\n",
    "                    return False\n",
    "            if current_char == '{':\n",
    "                if char != \"}\":\n",
    "                    return False\n",
    "            if current_char == '[':\n",
    "                if char != \"]\":\n",
    "                    return False\n",
    "    \n",
    "    if stack:\n",
    "        return False\n",
    "\n",
    "    return all(ord(c) < 128 for c in exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = \"((ö)\"\n",
    "verify_regex(regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e8bba4f2be892cbd4f39a9f240acc2c7ebb8cef7264d56c87dbb8c6b0bcbe231"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
